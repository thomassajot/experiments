{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13bdc6b6-6438-4823-941b-b77c5431133c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Import some additional JAX and dataloader helpers\n",
    "from jax.scipy.special import logsumexp\n",
    "from jax.example_libraries import optimizers\n",
    "\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "import mediapy as mpy\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "import numpy as onp\n",
    "import jax.numpy as np\n",
    "from jax import grad, jit, vmap, value_and_grad\n",
    "from jax import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28772d2b-907c-45d5-9c3d-59ee30fc26d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "# Generate key which is used to generate random numbers\n",
    "key = random.PRNGKey(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d25467a-6248-4a74-b392-105534ada093",
   "metadata": {},
   "source": [
    "# Attention layer\n",
    "\n",
    "$$\n",
    "\\text{Given } Q \\in \\mathbb{R}^{B \\times d_k}, K \\in \\mathbb{R}^{B \\times d_k}, V \\in \\mathbb{R}^{B \\times d_v} \\\\\n",
    "Attention(Q, K, V) = softmax \\left( \\frac{QK^T}{\\sqrt{d_k}} \\right) V\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5acdc3e7-93f7-4bc9-aab1-6344e7b8931a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from attention.layers.encoder import EncoderBlock\n",
    "import haiku as hk\n",
    "import jax.numpy as jnp\n",
    "import jax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c055eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x):\n",
    "    encoder = EncoderBlock(num_heads=2, key_size=16, value_size=32, model_size=8, name='blob')\n",
    "    return encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f80d95f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add got incompatible shapes for broadcasting: (8, 224, 224, 8), (8, 224, 224, 3).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m rng \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mPRNGKey(\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mones([\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m3\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m params \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39minit(rng, x)\n\u001b[1;32m      5\u001b[0m envoced \u001b[38;5;241m=\u001b[39m encoder\u001b[38;5;241m.\u001b[39mapply(params, rng, x)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Attention/lib/python3.9/site-packages/haiku/_src/transform.py:113\u001b[0m, in \u001b[0;36mwithout_state.<locals>.init_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minit_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 113\u001b[0m   params, state \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    114\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m state:\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf your transformed function uses `hk.\u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124mget,set}_state` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthen use `hk.transform_with_state`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Attention/lib/python3.9/site-packages/haiku/_src/transform.py:381\u001b[0m, in \u001b[0;36mtransform_with_state.<locals>.init_fn\u001b[0;34m(rng, *args, **kwargs)\u001b[0m\n\u001b[1;32m    379\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m base\u001b[38;5;241m.\u001b[39mnew_context(rng\u001b[38;5;241m=\u001b[39mrng) \u001b[38;5;28;01mas\u001b[39;00m ctx:\n\u001b[1;32m    380\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 381\u001b[0m     \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    382\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m jax\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mUnexpectedTracerError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    383\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m jax\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mUnexpectedTracerError(unexpected_tracer_hint) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36mencoder\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencoder\u001b[39m(x):\n\u001b[1;32m      2\u001b[0m     encoder \u001b[38;5;241m=\u001b[39m EncoderBlock(num_heads\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, key_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, value_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, model_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblob\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Attention/lib/python3.9/site-packages/haiku/_src/module.py:433\u001b[0m, in \u001b[0;36mwrap_method.<locals>.wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m   local_name \u001b[38;5;241m=\u001b[39m module_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    431\u001b[0m   f \u001b[38;5;241m=\u001b[39m stateful\u001b[38;5;241m.\u001b[39mnamed_call(f, name\u001b[38;5;241m=\u001b[39mlocal_name)\n\u001b[0;32m--> 433\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# Module names are set in the constructor. If `f` is the constructor then\u001b[39;00m\n\u001b[1;32m    436\u001b[0m \u001b[38;5;66;03m# its name will only be set **after** `f` has run. For methods other\u001b[39;00m\n\u001b[1;32m    437\u001b[0m \u001b[38;5;66;03m# than `__init__` we need the name before running in order to wrap their\u001b[39;00m\n\u001b[1;32m    438\u001b[0m \u001b[38;5;66;03m# execution with `named_call`.\u001b[39;00m\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m module_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Attention/lib/python3.9/site-packages/haiku/_src/module.py:284\u001b[0m, in \u001b[0;36mrun_interceptors\u001b[0;34m(bound_method, method_name, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;124;03m\"\"\"Runs any method interceptors or the original method.\"\"\"\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m interceptor_stack:\n\u001b[0;32m--> 284\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m ctx \u001b[38;5;241m=\u001b[39m MethodContext(module\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    287\u001b[0m                     method_name\u001b[38;5;241m=\u001b[39mmethod_name,\n\u001b[1;32m    288\u001b[0m                     orig_method\u001b[38;5;241m=\u001b[39mbound_method)\n\u001b[1;32m    289\u001b[0m interceptor_stack_copy \u001b[38;5;241m=\u001b[39m interceptor_stack\u001b[38;5;241m.\u001b[39mclone()\n",
      "File \u001b[0;32m~/projects/personal/experiments-1/src/attention/layers/encoder.py:26\u001b[0m, in \u001b[0;36mEncoderBlock.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     24\u001b[0m wip_layer_norm_attn \u001b[38;5;241m=\u001b[39m WIPLayerNorm()\n\u001b[1;32m     25\u001b[0m wip_layer_norm_linear \u001b[38;5;241m=\u001b[39m WIPLayerNorm()\n\u001b[0;32m---> 26\u001b[0m x \u001b[38;5;241m=\u001b[39m wip_layer_norm_attn(mha(query\u001b[38;5;241m=\u001b[39mx, key\u001b[38;5;241m=\u001b[39mx, value\u001b[38;5;241m=\u001b[39mx) \u001b[38;5;241m+\u001b[39m x)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m wip_layer_norm_linear(hk\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_size, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m)(x) \u001b[38;5;241m+\u001b[39m x)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Attention/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:6784\u001b[0m, in \u001b[0;36m_defer_to_unrecognized_arg.<locals>.deferring_binary_op\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m   6782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, _accepted_binop_types):\n\u001b[1;32m   6783\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m-> 6784\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbinary_op\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "    \u001b[0;31m[... skipping hidden 14 frame]\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Attention/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py:709\u001b[0m, in \u001b[0;36m_maybe_bool_binop.<locals>.fn\u001b[0;34m(x1, x2)\u001b[0m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfn\u001b[39m(x1, x2):\n\u001b[1;32m    708\u001b[0m   x1, x2 \u001b[38;5;241m=\u001b[39m _promote_args(numpy_fn\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, x1, x2)\n\u001b[0;32m--> 709\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlax_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx2\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m x1\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m bool_ \u001b[38;5;28;01melse\u001b[39;00m bool_lax_fn(x1, x2)\n",
      "    \u001b[0;31m[... skipping hidden 6 frame]\u001b[0m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/Attention/lib/python3.9/site-packages/jax/_src/lax/lax.py:1428\u001b[0m, in \u001b[0;36m_broadcasting_shape_rule\u001b[0;34m(name, *avals)\u001b[0m\n\u001b[1;32m   1426\u001b[0m     non_1s \u001b[38;5;241m=\u001b[39m {d \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m ds \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m core\u001b[38;5;241m.\u001b[39msymbolic_equal_dim(d, \u001b[38;5;241m1\u001b[39m)}\n\u001b[1;32m   1427\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(non_1s) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m-> 1428\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m got incompatible shapes for broadcasting: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1429\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mtuple\u001b[39m, shapes)))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   1430\u001b[0m     result_shape\u001b[38;5;241m.\u001b[39mappend(non_1s\u001b[38;5;241m.\u001b[39mpop() \u001b[38;5;28;01mif\u001b[39;00m non_1s \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(result_shape)\n",
      "\u001b[0;31mTypeError\u001b[0m: add got incompatible shapes for broadcasting: (8, 224, 224, 8), (8, 224, 224, 3)."
     ]
    }
   ],
   "source": [
    "encoder = hk.transform(encoder)\n",
    "rng = jax.random.PRNGKey(42)\n",
    "x = jnp.ones([8, 224, 224, 3])\n",
    "params = encoder.init(rng, x)\n",
    "encoded = encoder.apply(params, rng, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb5e72fe-3b94-4963-89f8-a72ae619f0d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[0.24472846, 0.66524094, 0.09003057],\n",
       "             [0.09003057, 0.24472846, 0.66524094]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(np.array([[1, 2, 0], [0, 1, 2]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b7cc3141-4eff-4a8c-aa7e-5e498a378271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(DeviceArray([[1.5],\n",
       "              [1.5]], dtype=float32),\n",
       " DeviceArray([[0.5, 0.5],\n",
       "              [0.5, 0.5]], dtype=float32),\n",
       " DeviceArray([[1, 1],\n",
       "              [0, 0]], dtype=int32))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = np.array([[0, 0, 1], [1, 0, 0]])\n",
    "k = np.array([[0, 0, 1], [0, 0, 1]])\n",
    "v = np.array([[1], [2]])\n",
    "attention_layer(q, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e05b3ec-c111-440d-b289-7257855f7bcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[0, 0, 1],\n",
       "             [1, 0, 0]], dtype=int32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5dada824-a1bc-4f49-ad0f-9b52ceb72949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[0, 0],\n",
       "             [0, 0],\n",
       "             [1, 1]], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "65e9fef4-c7dd-4f93-a87e-82fadf91fd61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[0.15055665, 0.02880473, 0.20766646, 0.14306472, 0.05770602],\n",
       "             [0.11433297, 0.02340085, 0.1404331 , 0.08351222, 0.03435331],\n",
       "             [0.12930429, 0.03125305, 0.18979977, 0.10114681, 0.03891528]],            dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_k = 10\n",
    "d_v = 5\n",
    "n = 3\n",
    "q = random.uniform(key, (n, d_k))\n",
    "k = random.uniform(key, (n, d_k))\n",
    "v = random.uniform(key, (n, d_v))\n",
    "\n",
    "attention_layer(q, k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9243fa0-07ca-4dd4-bb25-2383ef5da2de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
